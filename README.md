# SVM Fraud Detection Training Pipeline

A comprehensive SVM-based fraud detection system with multiple resampling strategies and kernel types for handling imbalanced financial transaction data.

## Overview

This project trains and evaluates **16 different SVM model configurations** to detect fraudulent financial transactions using the PaySim synthetic dataset. It systematically explores the impact of:

- **4 Resampling Strategies** (handling class imbalance)
- **4 SVM Kernel Types** (capturing different decision boundaries)

**Total Experiments:** 4 resampling Ã— 4 kernels = **16 model configurations**

---

## Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STEP 1: main.py                          â”‚
â”‚                    (Training Pipeline)                       â”‚
â”‚                                                              â”‚
â”‚  1. Download PaySim Dataset                                 â”‚
â”‚  2. Feature Engineering (30+ features)                      â”‚
â”‚  3. Apply Resampling Strategies                             â”‚
â”‚  4. Train 16 SVM Models                                     â”‚
â”‚  5. Evaluate & Save Results                                 â”‚
â”‚                                                              â”‚
â”‚  Outputs: checkpoints/, trained_models/, plots/             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  STEP 2: visualize.py                       â”‚
â”‚               (Visualization Pipeline)                       â”‚
â”‚                                                              â”‚
â”‚  1. Load Checkpoint Data                                    â”‚
â”‚  2. Calculate Class Distributions                           â”‚
â”‚  3. Generate Pie Charts                                     â”‚
â”‚  4. Display Statistics                                      â”‚
â”‚                                                              â”‚
â”‚  Outputs: plots/class_distribution_pie_charts.png           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> âš ï¸ **Important:** You **MUST** run `main.py` before running `visualize.py`

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.7+
- pip package manager

### Install Dependencies

```bash
pip install kagglehub numpy pandas scikit-learn imbalanced-learn matplotlib seaborn joblib
```

Or use the requirements file:

```bash
pip install -r requirements.txt
```

**requirements.txt:**
```
kagglehub>=0.1.0
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
imbalanced-learn>=0.9.0
matplotlib>=3.4.0
seaborn>=0.11.0
joblib>=1.0.0
```

---

## ğŸš€ Quick Start

### Run the Complete Pipeline

```bash
# Step 1: Train all models (required - first time may take 15-30 minutes)
python main.py

# Step 2: Generate visualization (optional - takes ~5 seconds)
python visualize.py
```

### Expected First-Run Timeline

1. **main.py** (~15-30 minutes)
   - Dataset download: ~2-5 minutes (470MB)
   - Feature engineering: ~1-2 minutes
   - Model training: ~10-20 minutes (varies by hardware)
   - Visualization generation: ~10 seconds

2. **visualize.py** (~5 seconds)
   - Loads cached data
   - Generates pie charts

### Subsequent Runs

Thanks to the checkpoint system, subsequent runs of `main.py` will be **much faster** (~30 seconds) as it skips already-completed steps.

---

## ğŸ“– Detailed Usage

### Step 1: Training Pipeline (`main.py`)

**Purpose:** Train and evaluate all SVM model configurations.

**What it does:**

1. **Data Acquisition**
   - Downloads PaySim synthetic financial transaction dataset from Kaggle
   - Samples 100,000 transactions (configurable)

2. **Feature Engineering**
   Creates 30+ features including:
   - **Transaction Type Features:** Encoded types, high-risk indicators
   - **Temporal Features:** Hour of day, day of month, night/weekend flags
   - **Merchant Features:** Merchant detection flags
   - **Balance Features:** Balance changes, ratios, mismatches
   - **Fraud Indicators:** Account draining, large transactions, anomalies
   - **Interaction Features:** Combined risk factors

3. **Resampling Strategies**
   Applies four approaches to handle class imbalance:
   
   | Strategy | Method | Effect |
   |----------|--------|--------|
   | `none` | Original data | ~99% non-fraud (baseline) |
   | `smote` | Synthetic oversampling | Balanced 50-50 split |
   | `undersample` | Random undersampling | Balanced but fewer samples |
   | `smotetomek` | SMOTE + Tomek links | Balanced with cleaner boundaries |

4. **Model Training**
   Trains SVM with four kernel types:
   - **Linear:** Fast, interpretable, works well for linearly separable data
   - **RBF:** Most popular, handles non-linear patterns well
   - **Polynomial:** Captures polynomial relationships (degree=3)
   - **Sigmoid:** Neural network-like decision boundaries

5. **Evaluation & Checkpointing**
   - Calculates comprehensive metrics
   - Saves models and results
   - Generates comparison visualizations

**Run Command:**
```bash
python main.py
```

**Outputs:**

```
checkpoints/
â”œâ”€â”€ processed_data_none_enhanced.pkl
â”œâ”€â”€ processed_data_smote_enhanced.pkl
â”œâ”€â”€ processed_data_undersample_enhanced.pkl
â”œâ”€â”€ processed_data_smotetomek_enhanced.pkl
â”œâ”€â”€ trained_model_none_linear_enhanced.pkl
â”œâ”€â”€ trained_model_none_rbf_enhanced.pkl
â””â”€â”€ ... (16 model files + 16 prediction files)

trained_models/
â”œâ”€â”€ none_linear/
â”‚   â”œâ”€â”€ model.pkl
â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â”œâ”€â”€ feature_columns.pkl
â”‚   â””â”€â”€ metadata.json
â””â”€â”€ ... (16 model directories)

plots/
â”œâ”€â”€ class_imbalance_comparison.png
â””â”€â”€ training_results.png
```

---

### Step 2: Visualization Pipeline (`visualize.py`)

**Purpose:** Generate pie charts showing class distribution for each resampling strategy.

**What it does:**

1. Loads preprocessed data from `checkpoints/`
2. Calculates fraud vs. non-fraud percentages
3. Creates 2Ã—2 grid of pie charts
4. Displays detailed statistics in console

**Prerequisites:**
- âš ï¸ `main.py` must be run first
- Requires checkpoint files to exist

**Run Command:**
```bash
python visualize.py
```

**Output:**

```
plots/
â””â”€â”€ class_distribution_pie_charts.png
```

---

## ğŸ“ Project Structure

```
fraud-detection-svm/
â”‚
â”œâ”€â”€ main.py                              # Training pipeline (run first)
â”œâ”€â”€ visualize.py                         # Visualization script (run second)
â”œâ”€â”€ README.md                            # This file
â”œâ”€â”€ requirements.txt                     # Python dependencies
â”‚
â”œâ”€â”€ checkpoints/                         # Auto-generated cache (can be deleted to retrain)
â”‚   â”œâ”€â”€ processed_data_*.pkl             # Preprocessed datasets (4 files)
â”‚   â”œâ”€â”€ trained_model_*.pkl              # Trained SVM models (16 files)
â”‚   â””â”€â”€ predictions_*.pkl                # Model predictions (16 files)
â”‚
â”œâ”€â”€ trained_models/                      # Production-ready models
â”‚   â”œâ”€â”€ none_linear/
â”‚   â”‚   â”œâ”€â”€ model.pkl                    # Serialized SVM model
â”‚   â”‚   â”œâ”€â”€ scaler.pkl                   # StandardScaler for preprocessing
â”‚   â”‚   â”œâ”€â”€ feature_columns.pkl          # Feature names list
â”‚   â”‚   â””â”€â”€ metadata.json                # Model metrics and info
â”‚   â””â”€â”€ ... (15 more model directories)
â”‚
â””â”€â”€ plots/                               # Generated visualizations
    â”œâ”€â”€ class_imbalance_comparison.png   # 4-panel class distribution analysis
    â”œâ”€â”€ training_results.png             # 6-panel performance comparison
    â””â”€â”€ class_distribution_pie_charts.png # 4-panel pie charts
```

---

## âœ¨ Features

### Intelligent Checkpoint System

- **Incremental Training:** Automatically resumes from the last completed step
- **Fast Iteration:** Skips preprocessing and training for already-completed models
- **Resumable:** Can stop and restart without losing progress
- **Storage Efficient:** Reuses cached data across experiments

**To retrain from scratch:**
```bash
rm -rf checkpoints/
python main.py
```

### Comprehensive Feature Engineering

**30+ engineered features** designed to capture fraud patterns:

| Category | Features | Examples |
|----------|----------|----------|
| Transaction Type | 4 features | Encoded type, transfer flag, cashout flag |
| Temporal | 4 features | Hour of day, night transaction indicator |
| Merchant | 2 features | Origin/destination merchant flags |
| Balance Analysis | 5 features | Balance changes, amount-to-balance ratios |
| Fraud Indicators | 5 features | Account draining, balance mismatches |
| Interactions | 2 features | Combined high-risk indicators |

### Automated Model Comparison

Generates comprehensive visualizations:

1. **class_imbalance_comparison.png**
   - Absolute sample counts
   - Percentage distributions
   - Imbalance ratios (linear & log scale)

2. **training_results.png**
   - F1-Score heatmap by strategy & kernel
   - ROC-AUC heatmap
   - Precision-Recall scatter plot
   - Training time comparison
   - Top 10 configurations ranking
   - Best model metrics breakdown

3. **class_distribution_pie_charts.png**
   - Side-by-side comparison of all resampling strategies
   - Percentage and absolute count labels

---

## âš™ï¸ Configuration

### Modifying Sample Size

Edit `main.py` around line 280:

```python
# Default: 100,000 transactions
SAMPLE_SIZE = 100000

# For faster testing:
SAMPLE_SIZE = 10000

# For full dataset:
# Remove or comment out the sampling line:
# df = df.sample(n=SAMPLE_SIZE, random_state=42)
```

### Adding Custom Resampling Strategies

Edit `main.py` around line 22:

```python
RESAMPLING_STRATEGIES = ['none', 'smote', 'undersample', 'smotetomek']

# Add custom strategies:
# RESAMPLING_STRATEGIES = ['none', 'smote', 'undersample', 'smotetomek', 'adasyn']
```

### Adding Custom Kernels

Edit `main.py` around line 23:

```python
KERNEL_TYPES = ['linear', 'rbf', 'poly', 'sigmoid']

# Add custom kernels or remove unwanted ones:
# KERNEL_TYPES = ['linear', 'rbf']  # Train only 2 kernels
```

### Adjusting SVM Hyperparameters

Edit `main.py` around line 300:

```python
svm_model = SVC(
    kernel=KERNEL,
    C=1.0,              # Regularization (try: 0.1, 1.0, 10.0)
    gamma='scale',      # Kernel coefficient (try: 'scale', 'auto', 0.001)
    class_weight='balanced',
    probability=True,
    random_state=42
)
```

---

## Output Examples

### Console Output: `main.py`

```
================================================================================
SVM FRAUD DETECTION TRAINING
Experiments: 4 resampling Ã— 4 kernels = 16 total
================================================================================

[NONE] Processing data...

============================================================
CLASS DISTRIBUTION - TRAINING SET (AFTER RESAMPLING)
Resampling Strategy: NONE
============================================================
Total Samples:       80,000
Non-Fraud (Class 0): 79,200 (99.00%)
Fraud (Class 1):     800 (1.00%)
Imbalance Ratio:     99.00:1 (non-fraud:fraud)
============================================================
  linear: trained (12.3s) F1=0.856
  rbf: trained (18.7s) F1=0.892
  poly: trained (22.1s) F1=0.873
  sigmoid: trained (15.4s) F1=0.841

[SMOTE] Loaded preprocessed data (158,400 train samples)

============================================================
CLASS DISTRIBUTION - TRAINING SET (AFTER RESAMPLING)
Resampling Strategy: SMOTE
============================================================
Total Samples:       158,400
Non-Fraud (Class 0): 79,200 (50.00%)
Fraud (Class 1):     79,200 (50.00%)
Imbalance Ratio:     1.00:1 (non-fraud:fraud)
============================================================
  linear: loaded F1=0.912
  rbf: loaded F1=0.945
  poly: loaded F1=0.928
  sigmoid: loaded F1=0.903

...

âœ“ Class imbalance comparison plot saved to: plots/class_imbalance_comparison.png
âœ“ Training results plot saved to: plots/training_results.png
```

### Console Output: `visualize.py`

```
======================================================================
CLASS DISTRIBUTION PERCENTAGES
======================================================================

NONE
  Total Samples: 80,000
  Non-Fraud: 99.00% (79,200 samples)
  Fraud:     1.00% (800 samples)

SMOTE
  Total Samples: 158,400
  Non-Fraud: 50.00% (79,200 samples)
  Fraud:     50.00% (79,200 samples)

UNDERSAMPLE
  Total Samples: 1,600
  Non-Fraud: 50.00% (800 samples)
  Fraud:     50.00% (800 samples)

SMOTETOMEK
  Total Samples: 156,234
  Non-Fraud: 49.87% (77,893 samples)
  Fraud:     50.13% (78,341 samples)

âœ“ Pie charts saved to: plots/class_distribution_pie_charts.png
```

---

## Performance Metrics

Each model is evaluated using:

### Classification Metrics
- **Accuracy:** Overall correctness
- **Precision:** True positives / (True positives + False positives)
- **Recall:** True positives / (True positives + False negatives)
- **F1-Score:** Harmonic mean of precision and recall

### Ranking Metrics
- **ROC-AUC:** Area under Receiver Operating Characteristic curve
- **PR-AUC:** Area under Precision-Recall curve (better for imbalanced data)

### Confusion Matrix Components
- **True Positives (TP):** Correctly identified frauds
- **False Positives (FP):** Non-frauds incorrectly flagged as fraud
- **True Negatives (TN):** Correctly identified non-frauds
- **False Negatives (FN):** Frauds missed by the model

### Metadata Saved for Each Model

```json
{
  "resampling_strategy": "smote",
  "kernel": "rbf",
  "training_date": "2024-12-04 10:30:45",
  "metrics": {
    "accuracy": 0.9876,
    "precision": 0.9234,
    "recall": 0.9456,
    "f1_score": 0.9344,
    "roc_auc": 0.9912,
    "pr_auc": 0.9823
  },
  "confusion_matrix": {
    "true_positives": 1520,
    "false_positives": 126,
    "true_negatives": 18234,
    "false_negatives": 120
  },
  "training_samples": 158400,
  "test_samples": 20000,
  "n_features": 32
}
```

---

---

## References

- **Dataset:** [PaySim Synthetic Financial Dataset](https://www.kaggle.com/datasets/ealaxi/paysim1)
- **SMOTE Paper:** Chawla et al. (2002) - "SMOTE: Synthetic Minority Over-sampling Technique"
- **SVM:** Cortes & Vapnik (1995) - "Support-vector networks"

---

**Happy Training! ğŸš€**
